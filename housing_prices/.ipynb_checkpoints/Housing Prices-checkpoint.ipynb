{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Price Prediction\n",
    "\n",
    "Competition: https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview  \n",
    "\n",
    "This is the notebook for my entry to the housing prices prediction competition on Kaggle.\n",
    "As of right now, my best submission has a best score (root mean logarithmic error) of 0.15797 and \n",
    "am 3301 on the leaderboard.\n",
    "\n",
    "My next steps are to try and use sklearn's builtin feature_selection funtions and PCA to see if these can improve the model's accuracy compared to my intuition.\n",
    "\n",
    "2/9/20 UPDATE: After learning more about Scikit-Learn and some of the tools that come with it, I made a pipeline to transform and fit the data and found marked improvements to my model! As of this update, I am now 3184 on the Leaderboard with a score of 0.15202. I decided to do cross validation with KFold because I felt that there weren't enough examples to simply split it into training and test sets. \n",
    "\n",
    "Next steps from this point on is to do some hyperparameter tuning, and also seeing if implementing more feature engineering/feature selection techniques will improve performance. For example, I may want to use some tools from the feature_selection package like SelectKBest or chi2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./train.csv\")\n",
    "test_data = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace current index with index from data frame\n",
    "train_data.index = train_data[\"Id\"]\n",
    "train_data = train_data.drop(\"Id\", axis=1)\n",
    "\n",
    "test_data.index = test_data[\"Id\"]\n",
    "test_data = test_data.drop(\"Id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.drop(\"SalePrice\", axis=1)\n",
    "y_train = train_data[\"SalePrice\"]\n",
    "\n",
    "# reset the Id column because KFold uses 0-indexing and the data uses 1-indexing\n",
    "x_train = x_train.reset_index().drop([\"Id\"], axis=1)\n",
    "x_train.index.name = \"Id\"\n",
    "\n",
    "y_train = y_train.reset_index().drop([\"Id\"], axis=1)\n",
    "y_train.index.name = \"Id\"\n",
    "y_train = np.ravel(y_train)\n",
    "\n",
    "# cols identified as not having enough values to be considered\n",
    "sparse_cols = [\"Alley\", \"FireplaceQu\", \"PoolQC\", \"Fence\", \"MiscFeature\"]\n",
    "x_train = x_train.drop(sparse_cols, axis=1)\n",
    "x_test = test_data.drop(sparse_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = x_train.select_dtypes(include=[np.number]).columns\n",
    "cat_cols = x_train.select_dtypes(exclude=np.number).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
       "       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
       "       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
       "       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
       "       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
       "       'MoSold', 'YrSold'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols, cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Training\n",
    "\n",
    "This is where I create a model and try to identify more features to see if the accuracy will improve. In the code below, you will see I implemented a function to check if the accuracy has increased from this run to the next. For categorical feature testing, I used the training data from the numerical features as a baseline to see if adding this categorical feature would increase the accuracy of the model. I checked the accuracy via Mean Squared Log Error (as it is in the Kaggle competition) and tested it against Support Vector Regression, Linear Regression, K Neighbors Regression, Decision Tree Regressor and Random Forest Regressor. \n",
    "\n",
    "From this experiment, I've found that the model with the best training accuracy is the Decision Tree Regressor, however, the Random Forest Regressor tended to do better on the validation set so I went with the RF Regressor in my Kaggle submissions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do KFold cross validation\n",
    "kfold = KFold(n_splits=5)\n",
    "kfold.get_n_splits(x_train)\n",
    "\n",
    "# pipeline for numerical features\n",
    "num_trans = make_pipeline(SimpleImputer(strategy=\"mean\"), StandardScaler(), PCA(n_components=24))\n",
    "\n",
    "# pipeline for categorical features\n",
    "cat_trans = make_pipeline(SimpleImputer(strategy=\"most_frequent\"), OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "preprocessor = ColumnTransformer(transformers=[(\"nums\", num_trans, num_cols), (\"cat\", cat_trans, cat_cols)])\n",
    "\n",
    "# keep track of which regressor trained gives the best score \n",
    "best_model = None\n",
    "min_score = float(\"inf\")\n",
    "for train, validation in kfold.split(x_train):    \n",
    "    reg = make_pipeline(preprocessor, RandomForestRegressor())\n",
    "    reg.fit(x_train.loc[train], y_train[train])\n",
    "    pred = reg.predict(x_train.loc[validation])\n",
    "    pred[pred < 0] = 0\n",
    "    score = mean_squared_log_error(y_train[validation], pred)\n",
    "    if score < min_score:\n",
    "        min_score = score\n",
    "        best_model = reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01556653747993075"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write our predictions to file\n",
    "ret = pd.DataFrame(columns=[\"Id\", \"SalePrice\"])\n",
    "ret[\"Id\"] = x_test.index\n",
    "ret[\"SalePrice\"] = y_pred\n",
    "ret.to_csv(path_or_buf=\"./submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
